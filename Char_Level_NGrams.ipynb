{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Char_Level_NGrams.ipynb","provenance":[],"collapsed_sections":["Mv-CXgI-YA2D","pUAPEJJ4Qxc5","4P4xIpLPb2E6","t2LWqKwzQpA7","VUlZKJx6Q_S8","6ab7rBA3U8U3","ThYgWfCXgsg7","tr2CA3Q3eY11","e793qQpRecCm"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6n8A5_sk7U57"},"source":["# Note: Partially adapted from Matthew Scharf's CIS 530 Homework #4 which he took in Fall 2020 with Professor Clayton Greenberg"]},{"cell_type":"markdown","metadata":{"id":"Mv-CXgI-YA2D"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UT0cGZO-OMqn","executionInfo":{"status":"ok","timestamp":1619552909756,"user_tz":240,"elapsed":19627,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"01899839175408915661"}},"outputId":"a0db6da6-9f5e-4ef2-80d0-980e5d135509"},"source":["import re, unicodedata, numpy as np, pandas as pd, pickle, os, math\n","\n","from numpy import random\n","from google.colab import files\n","\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pUAPEJJ4Qxc5"},"source":["# Download from kaggle"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":70},"id":"WXkdtPRpeY6J","executionInfo":{"status":"ok","timestamp":1619552928007,"user_tz":240,"elapsed":20287,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"01899839175408915661"}},"outputId":"dec147bd-8cff-4082-82ce-5a820cb020cc"},"source":["files.upload()\n","! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-61c42c4c-fd6a-452c-9bd5-a7af65fc5d39\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-61c42c4c-fd6a-452c-9bd5-a7af65fc5d39\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oTNnHAG_gMyT"},"source":["! chmod 600 /root/.kaggle/kaggle.json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uFHFdQmKw-1Z","executionInfo":{"status":"ok","timestamp":1619552939128,"user_tz":240,"elapsed":8079,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"01899839175408915661"}},"outputId":"ec6cd676-c73b-4f1e-927f-25c60c5c48f4"},"source":["!kaggle datasets download -d mswarbrickjones/reddit-selfposts"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading reddit-selfposts.zip to /content\n"," 99% 349M/352M [00:06<00:00, 60.5MB/s]\n","100% 352M/352M [00:06<00:00, 57.8MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f0cQ5P_OzhtR","executionInfo":{"status":"ok","timestamp":1619552948091,"user_tz":240,"elapsed":15640,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"01899839175408915661"}},"outputId":"1fccacaa-5782-41ae-d1f5-daf562af6437"},"source":["! unzip reddit-selfposts.zip -d data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  reddit-selfposts.zip\n","  inflating: data/rspct.tsv          \n","  inflating: data/subreddit_info.csv  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4P4xIpLPb2E6"},"source":["# Data Processing Functions"]},{"cell_type":"code","metadata":{"id":"TN59sYO-MI_o"},"source":["def preprocess_text(text):\n","    text = text.lower()\n","    text = unicodedata.normalize('NFD', text)\n","    text = text.encode('ascii', 'ignore')\n","    text = text.decode(\"utf-8\")\n","    text = re.sub(r'[^A-Za-z\\'\\s]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = re.sub(r' lb', ' ', text)\n","    text = text.strip()\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYPLSOt50f-u"},"source":["def get_data(path):\n","  print('Getting data')\n","  raw_df = pd.read_table(path+'rspct.tsv')\n","  sub_df = pd.read_csv(path+'subreddit_info.csv')\n","\n","  print('data read in. starting dataframe join:')\n","\n","  df = pd.merge(raw_df, sub_df, how='inner',on='subreddit')\\\n","            [['category_1','selftext']]\\\n","\n","  print('dataframes joined. starting text preprocessing:')\n","\n","  df.selftext = df.selftext.apply(preprocess_text)\n","\n","  df.category_1 = df.category_1.apply(lambda x: x.replace('/','&').replace(' ',''))\n","\n","  print('Text processed.')\n","  return df\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t2LWqKwzQpA7"},"source":["# Trie object definition"]},{"cell_type":"code","metadata":{"id":"F3lJJBqtQgGl"},"source":["class CountTree(object):\n","    ''' Stores observed ngrams for language modeling '''\n","\n","    def __init__(self, n=2):\n","        ''' Initialize the count tree; store n, d, and class_label '''\n","        #The order of the tree\n","        self.n = n\n","\n","        #The counts of each ngram\n","        self.d = {'': 0}\n","\n","        #The counts of characters following observed ngrams where\n","        #len(ngram) < order\n","        self.next = {}\n","\n","    def hist_prep(self,h,str_len):\n","      #Preproccessing the history to be the longest substring at the end \n","      #of the history which has length < order and has been seen before\n","      if len(h) <= str_len:\n","        ngram = h\n","      else:\n","        ngram = h[-str_len:]\n","    \n","      prior_count = self.get_count(ngram)\n","      \n","      if prior_count == 0 and ngram != '':\n","        return self.hist_prep(ngram[1:],str_len)\n","      else:\n","        return ngram\n","\n","    def add_to_counts(self,ngram):\n","      #Method for adding an ngram to counts\n","      try:\n","        self.d[ngram] += 1\n","      except KeyError:\n","        self.d[ngram] = 1\n","    \n","    def add_to_next(self,ngram,nxt):\n","      #Method for adding ngram and following character to 'next' dictionary\n","      try:\n","        self.next[(ngram,nxt)] +=1\n","      except KeyError:\n","        self.next[(ngram,nxt)] = 1\n","\n","    def update(self, text):\n","        ''' Update the count tree based on text '''\n","        \n","        str_ = '<'+text+'>'\n","\n","        #Get 0th level count and next\n","        self.d[''] += len(str_)\n","\n","        for char in str_:\n","          self.add_to_next('',char)  \n","\n","        #Get levels above 0\n","        if self.n > 0:\n","\n","          #For each level in the tree above 0\n","          for lvl in range(1,self.n+1):\n","\n","            #For each character sequence of length lvl\n","            for i in range(len(str_) - lvl + 1):\n","              ngram = str_[i:i+lvl]\n","              \n","              #Update ngram counts\n","              self.add_to_counts(ngram)\n","              \n","              #Checking to see that we are not at the last character sequence\n","              #or the last level\n","              \n","              if i < len(str_) - lvl and lvl < self.n:\n","                \n","                #If we are not, then we update next character counts\n","                nxt = str_[i+lvl]\n","                self.add_to_next(ngram,nxt)\n","                \n","\n","    def get_count(self, ngram):\n","        ''' Return the count of ngram '''\n","        try:\n","          count = self.d[ngram]\n","        except KeyError:\n","          count = 0\n","        return count\n","    \n","    def get_next(self, ngram, nxt):\n","        ''' Return the count of ngram '''\n","        assert len(nxt) ==  1\n","        try:\n","          count = self.next[(ngram,nxt)]\n","        except KeyError:\n","          count = 0\n","        return count\n","\n","    def get_extensions(self, ngram):\n","        ''' Return a list of tuples: extensions of h and their counts '''\n","\n","        #Gathering the 'next' counts that match the processed history\n","        return [(nxt,count) for ((pos_ngram, nxt), count) in self.next.items()\\\n","                if pos_ngram==ngram]\n","    \n","    def train(self, training_data):\n","      for text in training_data:\n","        self.update(text)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VUlZKJx6Q_S8"},"source":["# Text generation functions"]},{"cell_type":"code","metadata":{"id":"aREzsLj4Q-JO"},"source":["def random_char(count_tree, h):\n","    ''' Returns a random character to follow h by its distribution '''\n","    #Get random number for threshold\n","    r = random.random()\n","\n","    #Preprocess history (as described in hist_prep definition) to get ngram\n","    ngram = count_tree.hist_prep(h,count_tree.n-1)\n","\n","    #Get ngram count\n","    ttl_count = count_tree.get_count(ngram)\n","\n","    #Get list of next characters and counts\n","    next_list = count_tree.get_extensions(ngram)\n","\n","    #Convert counts to probabilities and sort\n","    distr = sorted([(nxt,count/ttl_count) for (nxt,count) in next_list],\n","                   key = lambda x: x[0])\n","\n","\n","    prob_count = 0\n","\n","    #Iterate over distribution\n","    for nxt, prob in distr:\n","\n","      #Sum up probabilites\n","      prob_count += prob\n","\n","      #Stop and return once we have exceeded random threshold\n","      if prob_count > r:\n","        return nxt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzg7Ut6jRBtg"},"source":["def random_text(count_tree, length):\n","    ''' Returns a random text with given length '''\n","    text = '<'\n","    next = ''\n","    counter = 0\n","    \n","    while next != '>' and counter < length:\n","      next = random_char(count_tree, text)\n","      text += next\n","      counter += 1\n","\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SL9uYXPdZZJ"},"source":["def generate_text_all_models(path,length):\n","  for cat in cats:\n","\n","    with open(path + cat + '.pickle', 'rb') as handle:\n","      mdl = pickle.load(handle)\n","    \n","    print('Generating text for category:',cat)\n","    print(random_text(mdl, length),'\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ab7rBA3U8U3"},"source":["# Training function"]},{"cell_type":"code","metadata":{"id":"hOaWJ-LNU-i8"},"source":["def train_models(df, out_path, cats, depth=2):\n","  \n","  print('Training models:')\n","  num_cats = len(cats)\n","\n","  for i, cat in enumerate(cats, 1):\n","    print('Category {}/{}:{}'.format(i,num_cats,cat))\n","    mdl = CountTree(n=depth)\n","    data = list(df[df.category_1 == cat].selftext)\n","\n","    mdl.train(data)\n","\n","    with open('{}{}.pickle'.format(out_path,cat), 'wb') as handle:\n","      pickle.dump(mdl, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","  \n","  print('Done training!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ThYgWfCXgsg7"},"source":["# Hyperparameters and training setup"]},{"cell_type":"code","metadata":{"id":"tIB4FAJz_icq"},"source":["cats = ['writing&stories',\n","'tv_show',\n","'autos',\n","'hardware&tools',\n","'electronics']\n","# 'video_game',\n","# 'crypto',\n","# 'sports',\n","# 'hobby',\n","# 'appearance'\n","# ,\n","# 'card_game',\n","# 'drugs',\n","# 'advice&question',\n","# 'social_group',\n","# 'anime&manga',\n","# 'sex&relationships',\n","# 'software',\n","# 'health',\n","# 'animals',\n","# 'arts',\n","# 'programming',\n","# 'rpg',\n","# 'books',\n","# 'parenting',\n","# 'education',\n","# 'company&website',\n","# 'profession',\n","# 'music',\n","# 'politics&viewpoint',\n","# 'stem',\n","# 'travel',\n","# 'geo',\n","# 'religion&supernatural',\n","# 'board_game',\n","# 'movies',\n","# 'food&drink',\n","# 'finance&money',\n","# 'meta']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NdW6FmVggLvI"},"source":["path = '/content/gdrive/MyDrive/CIS 522 Final Project/ngram_models/depth10/'\n","depth = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tr2CA3Q3eY11"},"source":["# Training models"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Odjae1qvmS2r","executionInfo":{"status":"ok","timestamp":1619553052804,"user_tz":240,"elapsed":75661,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"01899839175408915661"}},"outputId":"63dbecf8-01cf-469c-d11e-4c04bd631189"},"source":["%%time\n","df = get_data('data/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Getting data\n","data read in. starting dataframe join:\n","dataframes joined. starting text preprocessing:\n","Text processed.\n","CPU times: user 1min 13s, sys: 1.6 s, total: 1min 15s\n","Wall time: 1min 15s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2Z8uL_BY9WX","executionInfo":{"status":"ok","timestamp":1619554912291,"user_tz":240,"elapsed":596949,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"01899839175408915661"}},"outputId":"30be793c-9102-4d0e-b36b-13820f4b2bec"},"source":["%%time\n","train_models(df,path, [cats[0]], depth=depth)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training models:\n","Category 1/1:writing&stories\n","Done training!\n","CPU times: user 9min 41s, sys: 10.5 s, total: 9min 51s\n","Wall time: 9min 56s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e793qQpRecCm"},"source":["# Text generation"]},{"cell_type":"code","metadata":{"id":"XNOotXlKd-6N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619469121007,"user_tz":240,"elapsed":905096,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"04935457332437370856"}},"outputId":"8b7b93f7-3099-4ae3-c895-05d0f2627af9"},"source":["generate_text_all_models(path,100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Generating text for category: writing&stories\n","<a washable folder destiny is a new computer and i went home with me i have looked lb lb he's awkward \n","\n","Generating text for category: tv_show\n","<ok so i'm wondering if anyone else's opinion what happened so far even an answer and try not to ment \n","\n","Generating text for category: autos\n","<i have a volvo c t it is a handling and changed new pla from the second time this happen with these  \n","\n","Generating text for category: hardware&tools\n","<i looked around that much  i have some money   light control you have any question but i want   sold \n","\n","Generating text for category: electronics\n","<so been higher frequency it's also a wealth of information i have the police know some people buy on \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kK99aVnNhu6Z"},"source":["# Classification functions"]},{"cell_type":"code","metadata":{"id":"6VOuMPcyi9F1"},"source":["def ad_prob(count_tree, w, h, d,verbose=False):\n","    ''' Returns the probability of w given h '''\n","    if count_tree.n == 1:\n","      return count_tree.get_next('',w)/count_tree.get_count('')\n","    def disp(*text):\n","      if verbose:\n","        print(*text)\n","\n","    disp(\"w:\",w)\n","    disp(\"h:\",h)\n","    disp(\"d:\",d)\n","    if len(h) <= count_tree.n - 1:\n","      ngram = h\n","    else:\n","      ngram = h[-count_tree.n+1:]\n","    disp(\"ngram:\",ngram)\n","    count = count_tree.get_count(ngram)\n","    disp(\"count:\",count)\n","    next = count_tree.get_next(ngram,w)\n","    disp(\"next:\",next)\n","\n","    if ngram == '':\n","      disp(\"Empty Probability:\",next/count,'\\n')\n","      return next/count\n","    elif count == 0:\n","      disp(\"COUNT ZERO\")\n","      disp(\"\\n\")\n","      return ad_prob(count_tree, w, ngram[1:], d,verbose)\n","    else:\n","      beta_history = ngram[1:]\n","      disp(\"beta history:\",beta_history)\n","      if ngram[0] == '<':\n","        d = d[:len(ngram)] \n","      disc = d[-len(ngram)]\n","      disp(\"discount:\",disc)\n","      beta_prob = ad_prob(count_tree, w, beta_history, d,verbose)\n","      disp(\"beta_prob:\",beta_prob)\n","      adjstd_mle = max([next - disc, 0])/count\n","      disp(\"adjusted mle:\",adjstd_mle)\n","      lambda_ = (disc * len(count_tree.get_extensions(ngram)))/count\n","      disp(\"labmda_:\",lambda_)\n","      disp(\"Probability:\",adjstd_mle + (lambda_ * beta_prob))\n","      return adjstd_mle + (lambda_ * beta_prob)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-7JO4dujC1T"},"source":["def perplexity(count_tree, text,verbose=False):\n","    ''' Returns the perplexity of the given text '''\n","\n","    d = [.9 for i in range(count_tree.n-1)]\n","\n","    def disp(*text):\n","      if verbose:\n","        print(*text)\n","    \n","    text = '<' + preprocess_text(text) + '>'\n","    sup = 0\n","    disp(\"sup:\",0)\n","    for i in range(1,len(text)):\n","      h = text[:i]\n","      w = text[i]\n","      prb = ad_prob(count_tree, w, h, d,verbose)\n","      if prb == 0:\n","        return math.inf\n","      else:\n","        sup -= math.log(prb,2)\n","      disp(\"total sup:\",sup,'\\n')\n","    perp = 2**(sup/(len(text)-1))\n","    return perp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YS1FcTUUhuAV"},"source":["def classify(path, text):\n","  \n","  perp_list = []\n","\n","  for cat in cats:\n","\n","    print('Category: {}:'.format(cat))\n","\n","    with open(path + cat + '.pickle', 'rb') as handle:\n","      mdl = pickle.load(handle)\n","\n","    perp = perplexity(mdl, text)\n","\n","    print('Perplexity: {}\\n'.format(perp))\n","\n","    perp_list.append(perp)\n","  \n","  best_cat = cats[np.argmin(perp_list)]\n","  \n","  return best_cat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yH0cEtlpkof6"},"source":["# Classify Text"]},{"cell_type":"code","metadata":{"id":"Wd3D7LeEkmtw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619490049613,"user_tz":240,"elapsed":3382531,"user":{"displayName":"Matthew Scharf","photoUrl":"","userId":"04935457332437370856"}},"outputId":"7290930c-79b9-408a-cf99-1976907ee61a"},"source":["text = \"I just finished Scandal and I'm looking for a new show.\"\n","best_cat = classify(path, preprocess_text(text))\n","print(best_cat)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Category: writing&stories:\n","Perplexity: 3.4059914895981405\n","\n","Category: tv_show:\n","Perplexity: 2.2930703335426306\n","\n","Category: autos:\n","Perplexity: 3.4246802047921605\n","\n","Category: hardware&tools:\n","Perplexity: 3.1555841493501213\n","\n","Category: electronics:\n","Perplexity: 3.2564956621137218\n","\n","tv_show\n"],"name":"stdout"}]}]}